---
title:          Raptor-T :A Fused and Memory-Efficient Sparse Transformer for Long and Variable-Length Sequences
date:           2024-04-16 00:01:00 +0800
selected:       false
pub:            "IEEE Transactions on Computers (TC)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-custom badge-secondary">Journal</span><span class="badge badge-pill badge-custom badge-danger">CCF-A</span>'
pub_date:       "2024"

abstract: >-
    We present Raptor-T, a cutting-edge transformer framework designed for handling long and variable-length sequences. Raptor-T harnesses the power of the sparse transformer to reduce resource requirements for processing long sequences while also implementing system-level optimizations to accelerate inference performance. 
  
cover:          assets/images/covers/lcfm_lc.png
authors:
  - Hulin Wang
  - Donglin Yang
  - Yaqi Xia
  - Zheng Zhang
  - Qigang Wang
  - Jianping Fan
  - Xiaobo Zhou
  - Dazhao Chengâ€ 
links:
  Paper: https://ieeexplore.ieee.org/abstract/document/10500743
  # Poster: assets/images/poster/icml2024-ws.jpeg
---
