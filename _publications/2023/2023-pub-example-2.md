---
title:          MPipeMoE :Memory Efficient MoE for Pre-trained Models with Adaptive Pipeline Parallelism
date:           2023-05-01 00:01:00 +0800
selected:       false
pub:            "IEEE International Parallel and Distributed Processing Symposium (IPDPS)"
pub_last:       ' <span class="badge badge-pill badge-custom badge-primary">Conference</span><span class="badge badge-pill badge-custom badge-warning">CCF-B</span>'
pub_date:       "2023"
abstract: >-
  In this paper, we present the design and implementation of MPipeMoE, a high-performance library that accelerates MoE training with adaptive and memory-efficient pipeline parallelism.

cover:          assets/images/covers/pub_ipdps23.png
authors:
  - Zheng Zhang
  - Donglin Yang
  - Yaqi Xia
  - Liang Ding
  - Dacheng Tao
  - Xiaobo Zhou
  - Dazhao Chengâ€ 
links:
  Paper: https://ieeexplore.ieee.org/abstract/document/10177396
  # Cite: https://scholar.googleusercontent.com/scholar.bib?q=info:iAlQXgKqt_kJ:scholar.google.com/&output=citation&scisdr=ClHXww7fENKfuhjn6gU:AFWwaeYAAAAAZrXh8gWTCgTXYLbXUF43RFf8TP4&scisig=AFWwaeYAAAAAZrXh8r9WKk8jHsP4QwW0zXpcVHc&scisf=4&ct=citation&cd=-1&hl=en
---
